{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAVE_TO_FILE(df_, modelName,path):\n",
    "    df_.to_csv(path + 'mmingalov_kaggle_math_exam(' + modelName + ').csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_norm_fit(x):\n",
    "    res = (x - x.min()) / (x.max() - x.min())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels  # y_true\n",
    "        self.prediction = self.predict()  # y_pred\n",
    "        \n",
    "    def predict(self):\n",
    "        return np.mean(self.labels)\n",
    "    \n",
    "    def predict_dispersion(self):\n",
    "        return np.var(self.labels, ddof=1)\n",
    "    \n",
    "    def predict_std(self):\n",
    "        return np.std(self.labels, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "\n",
    "    def __init__(self, max_depth=10, max_leaf_qty=1024):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_leaf_qty = max_leaf_qty\n",
    "        self.tree = None\n",
    "\n",
    "    # дисперсия значений\n",
    "    def dispersion(self, labels):\n",
    "        return np.var(labels, ddof=1)\n",
    "    \n",
    "    # ср.кв.откл. значений\n",
    "    def standard_deviation(self, labels):\n",
    "        return np.std(labels, ddof=1)\n",
    "\n",
    "    # качество\n",
    "    def quality(self, left_labels, right_labels, current_dispersion):\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "        return current_dispersion - p * self.dispersion(left_labels) - (1 - p) * self.dispersion(right_labels)\n",
    "\n",
    "    # Ветвление в узле\n",
    "    def split(self, data, labels, index, t):\n",
    "    \n",
    "        left = np.where(data[:, index] <= t)\n",
    "        right = np.where(data[:, index] > t)\n",
    "        \n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "        \n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "    # Определение наилучшего разбиения\n",
    "    def find_best_split(self, data, labels):\n",
    "    \n",
    "        #  минимально допустимое количество объектов в узле\n",
    "        min_leaf = 5\n",
    "\n",
    "        current_dispersion = self.dispersion(labels)\n",
    "\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "    \n",
    "        n_features = data.shape[1]\n",
    "    \n",
    "        for idx in range(n_features):\n",
    "          # берем уникальные значения\n",
    "            t_values = np.unique([item[idx] for item in data])\n",
    "      \n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, idx, t)\n",
    "                #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "                if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_quality = self.quality(true_labels, false_labels, current_dispersion)\n",
    "        \n",
    "                #  выбираем порог, на котором получается максимальный прирост качества\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, idx\n",
    "\n",
    "        return best_quality, best_t, best_index\n",
    "\n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "    def build_tree(self, data, labels, tree_depth, max_depth=5, max_leaf_qty=32, min_per_leaf=5, classes_per_leaf=1, min_quality_gain=1e-4):\n",
    "\n",
    "        quality, t, index = self.find_best_split(data, labels)\n",
    "\n",
    "        #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "        if quality == 0:\n",
    "            return Leaf(data, labels)\n",
    "        \n",
    "        # Прекращаем, если кол-во элементов в листе <= min_per_leaf\n",
    "        if data.shape[0] <= min_per_leaf:\n",
    "            return Leaf(data, labels)\n",
    "\n",
    "        # Прекращаем, если кол-во классов в листе <= min_classes_per_leaf\n",
    "        if len(set(labels)) <= classes_per_leaf:\n",
    "            return Leaf(data, labels)\n",
    "        \n",
    "        # прекращаем рекурсию, когда достигнута максимальная глубина дерева\n",
    "        if tree_depth >= max_depth:\n",
    "            return Leaf(data, labels)\n",
    "\n",
    "        # Увеличиваем глубину дерева на 1\n",
    "        tree_depth += 1\n",
    "\n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        # Рекурсивно строим два поддерева\n",
    "        true_branch = self.build_tree(true_data, true_labels, tree_depth, max_depth)\n",
    "        false_branch = self.build_tree(false_data, false_labels, tree_depth, max_depth)\n",
    "\n",
    "        # Возвращаем узел\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "    def predict_object(self, obj, node):\n",
    "\n",
    "        #  Останавливаем рекурсию, если достигли листа\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.predict_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.predict_object(obj, node.false_branch)\n",
    "\n",
    "    def predict(self, data):\n",
    "    \n",
    "        val = []\n",
    "        for obj in data:\n",
    "            prediction = self.predict_object(obj, self.tree)\n",
    "            val.append(prediction)\n",
    "        return val\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        self.tree = self.build_tree(data, labels, 0, self.max_depth)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FOLDER = 'D:\\\\Cloud\\\\Git\\\\geekbrains-data-analysis-alg\\\\tutors-expected-math-exam-results\\\\'\n",
    "train = pd.read_csv(PATH_FOLDER + 'train.csv')\n",
    "test = pd.read_csv(PATH_FOLDER + 'test.csv')\n",
    "features = ['age','years_of_experience','lesson_price','qualification','physics',\n",
    "            'chemistry','biology','english','geography','history']\n",
    "\n",
    "X = np.array(calc_norm_fit(train[features]))# отбираем множество признаков и нормализуем\n",
    "#train_f = calc_std_fit(train[features])# отбираем множество признаков и стандартизируем\n",
    "y = np.array(train['mean_exam_points'])\n",
    "\n",
    "classification_data = X\n",
    "classification_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_data, valid_data, train_labels, valid_labels = model_selection.train_test_split(classification_data, \n",
    "                                                                                     classification_labels, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tree at 0x25cd62ed948>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tree.predict(train_data)\n",
    "y_valid_pred = tree.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187033745197206"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "coefficient_of_dermination = r2_score(train_labels, y_train_pred)\n",
    "coefficient_of_dermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7492276782067132"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficient_of_dermination = r2_score(valid_labels, y_valid_pred)\n",
    "coefficient_of_dermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(calc_norm_fit(test[features]))# отбираем множество признаков и нормализуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 202 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#финальный набор test, который нужно посчитать\n",
    "y_test_pred = tree.predict(X_test)\n",
    "#y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_test_pred)\n",
    "df.columns = ['mean_exam_points']\n",
    "df['Id'] = range(10000,len(df)+10000)\n",
    "df_save = df[['Id','mean_exam_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>55.329545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>65.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>51.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10003</td>\n",
       "      <td>89.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10004</td>\n",
       "      <td>89.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>19995</td>\n",
       "      <td>39.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>19996</td>\n",
       "      <td>79.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>19997</td>\n",
       "      <td>53.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>19998</td>\n",
       "      <td>64.586777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>19999</td>\n",
       "      <td>63.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  mean_exam_points\n",
       "0     10000         55.329545\n",
       "1     10001         65.894737\n",
       "2     10002         51.333333\n",
       "3     10003         89.333333\n",
       "4     10004         89.058824\n",
       "...     ...               ...\n",
       "9995  19995         39.045455\n",
       "9996  19996         79.750000\n",
       "9997  19997         53.614286\n",
       "9998  19998         64.586777\n",
       "9999  19999         63.500000\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TO_FILE(df_save,'DecisionTreeRegr', PATH_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FOLDER = 'D:\\\\Cloud\\\\Git\\\\geekbrains-data-analysis-alg\\\\tutors-expected-math-exam-results\\\\'\n",
    "train = pd.read_csv(PATH_FOLDER + 'train.csv')\n",
    "test = pd.read_csv(PATH_FOLDER + 'test.csv')\n",
    "train['ones'] = 1 #\n",
    "test['ones'] = 1 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# интерквартильный размах\n",
    "def IQ_processing(df_, list_):\n",
    "    for i in list_:\n",
    "        c = i\n",
    "        IQP = IQ_param_get(df_,c)\n",
    "        print(c,IQP)\n",
    "        df_[(df_[c] < IQP['low_border']) | (df_[c]> IQP['high_border'])]\n",
    "        df_.loc[df_[c] > IQP['high_border'], c] = IQP['median']\n",
    "        df_.loc[df_[c] < IQP['low_border'], c] = IQP['median']\n",
    "        print('count after procesing:',df_[(df_[c] < IQP['low_border']) | (df_[c]> IQP['high_border'])][c].count())\n",
    "\n",
    "        # Обработка выбросов -- медианы для значений за пределами \n",
    "def IQ_param_get(df_, column_):\n",
    "    m = df_[column_].median()\n",
    "    c = column_\n",
    "    IQ=df_[c].describe()['75%']-df_[c].describe()['25%']\n",
    "    \n",
    "    low_border=df_[c].describe()['25%']-IQ*1.5\n",
    "    \n",
    "    high_border=df_[c].describe()['75%']+IQ*1.5\n",
    " \n",
    "    count1 = df_[(df_[c] < low_border) | (df_[c]> high_border)][c].count()\n",
    "    \n",
    "    result = {\n",
    "        'IQ':IQ,\n",
    "        'low_border':low_border,\n",
    "        'high_border':high_border,\n",
    "        'count': count1,\n",
    "        'median': m\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataframe train\n",
      "lesson_price {'IQ': 850.0, 'low_border': 25.0, 'high_border': 3425.0, 'count': 25, 'median': 1500.0}\n",
      "count after procesing: 0\n",
      "age {'IQ': 11.0, 'low_border': 23.5, 'high_border': 67.5, 'count': 77, 'median': 46.0}\n",
      "count after procesing: 0\n"
     ]
    }
   ],
   "source": [
    "# интерквартильный размах\n",
    "list = ['lesson_price','age']\n",
    "print('processing dataframe train')\n",
    "IQ_processing(train, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(calc_norm_fit(train[features]))# отбираем множество признаков и нормализуем\n",
    "#train_f = calc_std_fit(train[features])# отбираем множество признаков и стандартизируем\n",
    "y = np.array(train['mean_exam_points'])\n",
    "\n",
    "classification_data = X\n",
    "classification_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_data, valid_data, train_labels, valid_labels = model_selection.train_test_split(classification_data, \n",
    "                                                                                     classification_labels, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Tree at 0x25cd732e788>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tree.predict(train_data)\n",
    "y_valid_pred = tree.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158121115627444"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "coefficient_of_dermination = r2_score(train_labels, y_train_pred)\n",
    "coefficient_of_dermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446713164004017"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficient_of_dermination = r2_score(valid_labels, y_valid_pred)\n",
    "coefficient_of_dermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
